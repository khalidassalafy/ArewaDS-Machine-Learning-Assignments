{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuisine Classifier 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second classification lesson, you will explore more ways to classify numeric data. You will also learn about the ramifications for choosing one classifier over the other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "We have to  load the cleaned dataset and  divide it into X and y dataframes, ready for the model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 cuisine  almond  angelica  anise  anise_seed  apple   \n",
       "0           0  indian       0         0      0           0      0  \\\n",
       "1           1  indian       1         0      0           0      0   \n",
       "2           2  indian       0         0      0           0      0   \n",
       "3           3  indian       0         0      0           0      0   \n",
       "4           4  indian       0         0      0           0      0   \n",
       "\n",
       "   apple_brandy  apricot  armagnac  ...  whiskey  white_bread  white_wine   \n",
       "0             0        0         0  ...        0            0           0  \\\n",
       "1             0        0         0  ...        0            0           0   \n",
       "2             0        0         0  ...        0            0           0   \n",
       "3             0        0         0  ...        0            0           0   \n",
       "4             0        0         0  ...        0            0           0   \n",
       "\n",
       "   whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "0                        0     0     0    0      0       0         0  \n",
       "1                        0     0     0    0      0       0         0  \n",
       "2                        0     0     0    0      0       0         0  \n",
       "3                        0     0     0    0      0       0         0  \n",
       "4                        0     0     0    0      0       1         0  \n",
       "\n",
       "[5 rows x 382 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cuisines_df = pd.read_csv(\"data/cleaned_cuisines.csv\")\n",
    "cuisines_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the X and y coordinates into two dataframes for training. cuisine can be the labels dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    indian\n",
       "1    indian\n",
       "2    indian\n",
       "3    indian\n",
       "4    indian\n",
       "Name: cuisine, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisines_label_df = cuisines_df['cuisine']\n",
    "cuisines_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>artemisia</th>\n",
       "      <th>artichoke</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   almond  angelica  anise  anise_seed  apple  apple_brandy  apricot   \n",
       "0       0         0      0           0      0             0        0  \\\n",
       "1       1         0      0           0      0             0        0   \n",
       "2       0         0      0           0      0             0        0   \n",
       "3       0         0      0           0      0             0        0   \n",
       "4       0         0      0           0      0             0        0   \n",
       "\n",
       "   armagnac  artemisia  artichoke  ...  whiskey  white_bread  white_wine   \n",
       "0         0          0          0  ...        0            0           0  \\\n",
       "1         0          0          0  ...        0            0           0   \n",
       "2         0          0          0  ...        0            0           0   \n",
       "3         0          0          0  ...        0            0           0   \n",
       "4         0          0          0  ...        0            0           0   \n",
       "\n",
       "   whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "0                        0     0     0    0      0       0         0  \n",
       "1                        0     0     0    0      0       0         0  \n",
       "2                        0     0     0    0      0       0         0  \n",
       "3                        0     0     0    0      0       0         0  \n",
       "4                        0     0     0    0      0       1         0  \n",
       "\n",
       "[5 rows x 380 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)\n",
    "cuisines_feature_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A classification map\n",
    "Previously, you learned about the various options you have when classifying data using Microsoft's cheat sheet. Scikit-learn offers a similar, but more granular cheat sheet that can further help narrow down your estimators (another term for classifiers):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The plan\n",
    "This map is very helpful once you have a clear grasp of your data, as you can 'walk' along its paths to a decision:\n",
    "\n",
    "1. We have >50 samples\n",
    "2. We want to predict a category\n",
    "3. We have labeled data\n",
    "4. We have fewer than 100K samples\n",
    "     âœ¨ We can choose a Linear SVC\n",
    "4. If that doesn't work, since we have numeric data\n",
    "    We can try a âœ¨ KNeighbors Classifier\n",
    "5. If that doesn't work, try âœ¨ SVC and âœ¨ Ensemble Classifiers\n",
    "This is a very helpful trail to follow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - split the data\n",
    "Following this path, we should start by importing some libraries to use.\n",
    "\n",
    "Import the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split your training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC classifier\n",
    "Support-Vector clustering (SVC) is a child of the Support-Vector machines family of ML techniques (learn more about these below). In this method, you can choose a 'kernel' to decide how to cluster the labels. The 'C' parameter refers to 'regularization' which regulates the influence of parameters. The kernel can be one of several; here we set it to 'linear' to ensure that we leverage linear SVC. Probability defaults to 'false'; here we set it to 'true' to gather probability estimates. We set the random state to '0' to shuffle the data to get probabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - apply a linear SVC\n",
    "Start by creating an array of classifiers. You will add progressively to this array as we test.\n",
    "\n",
    "Start with a Linear SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model using the Linear SVC and print out a report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) for Linear SVC: 77.5% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.71      0.68      0.69       263\n",
      "      indian       0.87      0.87      0.87       233\n",
      "    japanese       0.71      0.78      0.75       226\n",
      "      korean       0.85      0.73      0.78       226\n",
      "        thai       0.76      0.82      0.79       251\n",
      "\n",
      "    accuracy                           0.77      1199\n",
      "   macro avg       0.78      0.78      0.78      1199\n",
      "weighted avg       0.78      0.77      0.77      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is pretty good!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Neighbors classifier\n",
    "K-Neighbors is part of the \"neighbors\" family of ML methods, which can be used for both supervised and unsupervised learning. In this method, a predefined number of points is created and data are gathered around these points such that generalized labels can be predicted for the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - apply the K-Neighbors classifier\n",
    "The previous classifier was good, and worked well with the data, but maybe we can get better accuracy. Try a K-Neighbors classifier.\n",
    "\n",
    "Add a line to your classifier array (add a comma after the Linear SVC item):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0), 'KNN classifier': KNeighborsClassifier(C)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) for Linear SVC: 77.5% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.71      0.68      0.69       263\n",
      "      indian       0.87      0.87      0.87       233\n",
      "    japanese       0.71      0.78      0.75       226\n",
      "      korean       0.85      0.73      0.78       226\n",
      "        thai       0.76      0.82      0.79       251\n",
      "\n",
      "    accuracy                           0.77      1199\n",
      "   macro avg       0.78      0.78      0.78      1199\n",
      "weighted avg       0.78      0.77      0.77      1199\n",
      "\n",
      "Accuracy (train) for KNN classifier: 72.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.68      0.62      0.65       263\n",
      "      indian       0.86      0.85      0.85       233\n",
      "    japanese       0.58      0.81      0.67       226\n",
      "      korean       0.88      0.54      0.67       226\n",
      "        thai       0.73      0.80      0.76       251\n",
      "\n",
      "    accuracy                           0.72      1199\n",
      "   macro avg       0.74      0.72      0.72      1199\n",
      "weighted avg       0.74      0.72      0.72      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a little worse!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier\n",
    "Support-Vector classifiers are part of the Support-Vector Machine family of ML methods that are used for classification and regression tasks. SVMs \"map training examples to points in space\" to maximize the distance between two categories. Subsequent data is mapped into this space so their category can be predicted."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - apply a Support Vector Classifier\n",
    "Let's try for a little better accuracy with a Support Vector Classifier.\n",
    "\n",
    "Add a comma after the K-Neighbors item, and then add this line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0), 'KNN classifier': KNeighborsClassifier(C), 'SVC': SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) for Linear SVC: 77.5% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.71      0.68      0.69       263\n",
      "      indian       0.87      0.87      0.87       233\n",
      "    japanese       0.71      0.78      0.75       226\n",
      "      korean       0.85      0.73      0.78       226\n",
      "        thai       0.76      0.82      0.79       251\n",
      "\n",
      "    accuracy                           0.77      1199\n",
      "   macro avg       0.78      0.78      0.78      1199\n",
      "weighted avg       0.78      0.77      0.77      1199\n",
      "\n",
      "Accuracy (train) for KNN classifier: 72.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.68      0.62      0.65       263\n",
      "      indian       0.86      0.85      0.85       233\n",
      "    japanese       0.58      0.81      0.67       226\n",
      "      korean       0.88      0.54      0.67       226\n",
      "        thai       0.73      0.80      0.76       251\n",
      "\n",
      "    accuracy                           0.72      1199\n",
      "   macro avg       0.74      0.72      0.72      1199\n",
      "weighted avg       0.74      0.72      0.72      1199\n",
      "\n",
      "Accuracy (train) for SVC: 81.2% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.75      0.73      0.74       263\n",
      "      indian       0.88      0.91      0.90       233\n",
      "    japanese       0.79      0.80      0.80       226\n",
      "      korean       0.86      0.75      0.80       226\n",
      "        thai       0.79      0.87      0.83       251\n",
      "\n",
      "    accuracy                           0.81      1199\n",
      "   macro avg       0.81      0.81      0.81      1199\n",
      "weighted avg       0.81      0.81      0.81      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is quite good!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Classifiers\n",
    "Let's follow the path to the very end, even though the previous test was quite good. Let's try some 'Ensemble Classifiers, specifically Random Forest and AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0), 'KNN classifier': KNeighborsClassifier(C), 'SVC': SVC(), 'RFST': RandomForestClassifier(n_estimators=100),\n",
    "  'ADA': AdaBoostClassifier(n_estimators=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) for Linear SVC: 77.5% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.71      0.68      0.69       263\n",
      "      indian       0.87      0.87      0.87       233\n",
      "    japanese       0.71      0.78      0.75       226\n",
      "      korean       0.85      0.73      0.78       226\n",
      "        thai       0.76      0.82      0.79       251\n",
      "\n",
      "    accuracy                           0.77      1199\n",
      "   macro avg       0.78      0.78      0.78      1199\n",
      "weighted avg       0.78      0.77      0.77      1199\n",
      "\n",
      "Accuracy (train) for KNN classifier: 72.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.68      0.62      0.65       263\n",
      "      indian       0.86      0.85      0.85       233\n",
      "    japanese       0.58      0.81      0.67       226\n",
      "      korean       0.88      0.54      0.67       226\n",
      "        thai       0.73      0.80      0.76       251\n",
      "\n",
      "    accuracy                           0.72      1199\n",
      "   macro avg       0.74      0.72      0.72      1199\n",
      "weighted avg       0.74      0.72      0.72      1199\n",
      "\n",
      "Accuracy (train) for SVC: 81.2% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.75      0.73      0.74       263\n",
      "      indian       0.88      0.91      0.90       233\n",
      "    japanese       0.79      0.80      0.80       226\n",
      "      korean       0.86      0.75      0.80       226\n",
      "        thai       0.79      0.87      0.83       251\n",
      "\n",
      "    accuracy                           0.81      1199\n",
      "   macro avg       0.81      0.81      0.81      1199\n",
      "weighted avg       0.81      0.81      0.81      1199\n",
      "\n",
      "Accuracy (train) for RFST: 83.3% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.81      0.73      0.77       263\n",
      "      indian       0.90      0.94      0.92       233\n",
      "    japanese       0.82      0.83      0.82       226\n",
      "      korean       0.84      0.77      0.80       226\n",
      "        thai       0.81      0.90      0.85       251\n",
      "\n",
      "    accuracy                           0.83      1199\n",
      "   macro avg       0.83      0.83      0.83      1199\n",
      "weighted avg       0.83      0.83      0.83      1199\n",
      "\n",
      "Accuracy (train) for ADA: 67.4% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.65      0.41      0.50       263\n",
      "      indian       0.87      0.83      0.85       233\n",
      "    japanese       0.58      0.59      0.59       226\n",
      "      korean       0.56      0.79      0.65       226\n",
      "        thai       0.74      0.78      0.76       251\n",
      "\n",
      "    accuracy                           0.67      1199\n",
      "   macro avg       0.68      0.68      0.67      1199\n",
      "weighted avg       0.68      0.67      0.67      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is very good, especially for Random Forest!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method of Machine Learning \"combines the predictions of several base estimators\" to improve the model's quality. In our example, we used Random Trees and AdaBoost.\n",
    "\n",
    "Random Forest, an averaging method, builds a 'forest' of 'decision trees' infused with randomness to avoid overfitting. The n_estimators parameter is set to the number of trees.\n",
    "\n",
    "AdaBoost fits a classifier to a dataset and then fits copies of that classifier to the same dataset. It focuses on the weights of incorrectly classified items and adjusts the fit for the next classifier to correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
