{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Textblob: A Simple Library for Natural Language Processing (NLP)"
      ],
      "metadata": {
        "id": "ZQO3yaV_qiq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction:\n",
        "NLP is branch of Computational Linguistics that focuses on making computers interact with people through human language. For example,  computer dictation- where you dictate to your computer and the voice is processed to text.\n",
        "\n",
        "For computers to be able to process and understand text data, it involves many NLP tasks such as tokenization, noun phrase extraction parts-of-speech targing,  sentiment analysis, translation etc.\n",
        "\n",
        "But Python offers  various libraries for performing Natural Language Processing tasks in a convenient way . One of the most prominent and easy-to-use libraries for processing textual data is TextBlob.\n",
        "\n",
        "This blog will walks us through some important NLP tasks using the textblob library."
      ],
      "metadata": {
        "id": "8iA5VNvHqpGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install textblob:\n",
        "Let's start  by installing the library using PIP:"
      ],
      "metadata": {
        "id": "nebMh5VprrZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0jLxWvFrPbz",
        "outputId": "0201b45c-6447-4d8b-a2e3-a33c045052a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will install the library as well as the necessary NLTK (Natural Language Toolkit) corpora.\n",
        "\n",
        "To download minimum corpora instead, run:"
      ],
      "metadata": {
        "id": "jYQ4GbZ6sNR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python -m textblob.download_corpora lite"
      ],
      "metadata": {
        "id": "pGD_xewcsVZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To install with conda:"
      ],
      "metadata": {
        "id": "3rCsV2QZsbE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conda install -c conda-forge textblob\n",
        "python -m textblob.download_corpora"
      ],
      "metadata": {
        "id": "0HE3cPtssu0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some NLP Tasks with TextBlob:\n",
        "Here we are going to look at some fundamental techniques that one must know in NLP.   We'll explain each concept briefly and show ho to do it using textblob."
      ],
      "metadata": {
        "id": "9Z8mwHVOswfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Tokenization:\n",
        "Most NLP tasks starts by splitting the text into tokens (chuncks of information). This is called tokenization. A tokenization can be sentences-level, word-level,  sub-word-level or character-level.\n",
        "\n",
        "The following code imports the textblob library:"
      ],
      "metadata": {
        "id": "5M4AEbBOtAaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "Us93B56at4bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then create a textblob object and assigned a text to it:"
      ],
      "metadata": {
        "id": "_zKt7JI3t3Ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text = TextBlob(\"I am reading a blog post on Medium. I am loving it!\")"
      ],
      "metadata": {
        "id": "TFU4AEjMuc9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our TextBlob is ready, let’s perform some word-level and sentence-level tokenization. We can easily break down the sentences into words attribute:"
      ],
      "metadata": {
        "id": "9mqUfzbFut_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5owB6iEvVRp",
        "outputId": "5b80dff7-086b-4aed-8671-bc94bd7f3e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['I', 'am', 'reading', 'a', 'blog', 'post', 'on', 'Medium', 'I', 'am', 'loving', 'it'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For sentences:"
      ],
      "metadata": {
        "id": "kr7sUVAlwV1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4clzqgfSwZlZ",
        "outputId": "8514013b-8042-4370-f55b-7b66057d369a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence(\"I am reading a blog post on Medium.\"), Sentence(\"I am loving it!\")]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Part-of -speech  Tagging :\n",
        "Tokenized words are tagged as parts of speech- noun, verb or adverb. This helps recognize what words are related in a sentence. Let’s try the PoS tagging operation with the “my_text” object:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z7ms1aXoxIai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cOxY9raxrPZ",
        "outputId": "1df64df6-e8a0-4533-edbf-ff5c3f75c325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('reading', 'VBG'),\n",
              " ('a', 'DT'),\n",
              " ('blog', 'NN'),\n",
              " ('post', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('Medium', 'NNP'),\n",
              " ('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('loving', 'VBG'),\n",
              " ('it', 'PRP')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Word and phrase frequencies:\n",
        "We can buid a dictionary of word that interests us to know how often it appears in the text. The “word_counts” operation returns the number of counts of a particular word in the sentence:"
      ],
      "metadata": {
        "id": "UEl6kbV3x-p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "betty = TextBlob(\"Betty Botter bought some butter. But she said the Butter’s bitter. If I put it in my batter, it will make my batter bitter. But a bit of better butter will make my batter better.\")\n",
        "betty.word_counts['butter']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAqxqfRUyUHj",
        "outputId": "6bf54864-641d-4238-a02c-5ab8f5ac9b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Noun phrase extraction:\n",
        "To understand the meaning of a sentence,  we extract the noun phrase- identifying su subject or object of the sentence. We often identify nouns to have \"a\", \"an\" or \"the\" preceding them."
      ],
      "metadata": {
        "id": "7P7m6-BuyfnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s say we want to extract the noun phrases in our sentences. This can easily be done using the noun phrases property:\n",
        "\n"
      ],
      "metadata": {
        "id": "bpy2bxpZys0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.noun_phrases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWvyaG0fy0yQ",
        "outputId": "4d429e82-48bf-422a-f730-625bf99cb481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['blog post', 'medium'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Sentiment Analysis :\n",
        "We can analyze a text or sentence for sentiment- how positive or negative it is. We can measure sentiment in polarity: -0 to 1 (negative to positive),  or in subjectivity and objectivity: 0 to 1 (most objective to most subjective):"
      ],
      "metadata": {
        "id": "17ItGHY9zAIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4pTuRzpzLWs",
        "outputId": "c018b269-30cd-4c1e-fe91-d59cb55dbc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=0.75, subjectivity=0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Inflection:\n",
        "Takes a word to find singular or plural of it:"
      ],
      "metadata": {
        "id": "lm3Bf0lqzcTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_text.words[4].pluralize() # the word \"blog\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9kvObILBzt3u",
        "outputId": "dd661da1-515c-40eb-e8cd-13180c08c62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'blogs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Lemmatization:\n",
        "Given a set of words,  a lemma is their root. For example,  flew, flies and flying have a lemma of the verb \"fly\"."
      ],
      "metadata": {
        "id": "WJjxKV40z2y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "w = Word(\"radii\")\n",
        "w.lemmatize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s-fb6Umq0QIB",
        "outputId": "fe2df38e-0f6d-4bd2-b33e-b9726730b689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'radius'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Definition:\n",
        "TextBlob also gives the functionality of defining the given word. The property called “definitions” does the job for it:\n",
        "\n"
      ],
      "metadata": {
        "id": "b3wUeEom0Vus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Word(\"blog\").definitions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7f5LtYC0jVf",
        "outputId": "6f7a8694-cf7e-4d14-c537-4f9df3f3ef86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a shared on-line journal where people can post diary entries about their personal experiences and hobbies',\n",
              " 'read, write, or edit a shared on-line journal']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Spelling correction:\n",
        "The spell check operation is performed by the “correct()” method. It uses the classic approach of Peter Norvig’s “How to Write a Spelling Corrector?“"
      ],
      "metadata": {
        "id": "KY-89C--0343"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_sentence = TextBlob(\"I am not in denger. I am the dyangr.\")\n",
        "my_sentence.correct()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTvACzBW1IpE",
        "outputId": "ffaf9b6b-7866-48b7-8fba-71a358dd7b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"I am not in danger. I am the danger.\")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Synsets:\n",
        "\n",
        "The “synsets” property returns a list of synset objects for a particular word:\n",
        "\n"
      ],
      "metadata": {
        "id": "7pEhsA341aN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = Word(\"phone\")\n",
        "word.synsets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZQwqEu31qzs",
        "outputId": "c9c39b43-1478-4906-9448-4fcecf151811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('telephone.n.01'),\n",
              " Synset('phone.n.02'),\n",
              " Synset('earphone.n.01'),\n",
              " Synset('call.v.03')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}